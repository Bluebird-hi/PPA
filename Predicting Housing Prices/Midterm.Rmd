---
title: "Predicting Housing Prices"
subtitle: "Philadelphia, 2022"
author: "Guangze Sun & Luming Xu"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    theme: spacelab
    toc_float: true
    toc_depth: 2
    code_folding: hide
    number_sections: true
bibliography: references.bib
---

<style type="text/css">

body, td {
   font-size: 16px;
}
code.r{
  font-size: 14px;
}
pre {
  font-size: 14px
}
</style>

```{r setup, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = FALSE, fig.show = "asis",
    fig.align = "center") 
options(scipen=999)

# Load some libraries
library(tidyverse)
library(tidycensus)
library(stringr)
library(dplyr)
library(lubridate)
library(sf)
library(stargazer)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot)
library(corrr)      
library(kableExtra)
library(jtools)     
library(ggstance) 
library(ggpubr)    
library(broom.mixed) 
library(glue)
library(classInt)
library(viridis)
library(patchwork)
library(corrplot)


source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- colorRampPalette(c("#6D9EC1", "#E46726"))(5)
```

# Introduction

An improved prediction model for home prices helps stakeholders and government agencies in making better housing policy and marketing decisions. For Zillow, one of the leading real estate companies in United States, developing an accurate, generalizable model for home prices is crucial to providing effective services to customers and enhancing the company’s competitiveness in the industry. However, this is a challenging task as numerous factors affect home prices, and no single model could cover all of them. This study seeks to create a more comprehensive home price model for Philadelphia, aiming to increase both accuracy and generalizability to benefit homebuyers, investors, the company and policymakers.

To achieve this, we applied the Hedonic Pricing Model, which accounts for internal characteristics, amenities/public services and spatial structure to determine property prices. Ordinary Least Square (OLS) regression forms the core of the model, following data cleaning, filtering and reclassification. Tests are conducted to evaluate the accuracy and generalizability of the model.

Overall, our model takes a step forward by including local characteristics like citywide spatial structures and neighborhood contexts, effectively predicts 76% of the variation in housing prices, achieves high accuracy for sales priced below $1,000,000, and controls mean absolute percentage error (MAPE) to about 36% without introducing more complex algorithms. However, the model shows less consistency and slight spatial autocorrelation, suggesting unaccounted factors. At the urban scale, North and West Philadelphia demonstrate poor predictions, indicating less generalizability towards low-priced neighborhoods and low-income tracts. Our model could be applied for predicting mid-range housing prices. Additional socioeconomic factors and non-linear regression techniques could be explored to develop the model.

# Data

Before modeling, we processed the data through data gathering from open portals, exploratory data analysis, and feature engineering.

## Data Collection

We reviewed previous studies to identify possible explanatory variables. Following the Hedonic Pricing Model, we sourced internal characteristics from the original dataset, gathered data on amenities (access to various spaces and services) through Open Data Philly portal, and accessed census data to grasp local contexts. Both continuous and categorial data are incorporated, and we chose the average distance to the 5 nearest crimes as an indicator of crime rate after comparing various metrics.[@zaki2022house;@lin2019implementing;@li2021understanding;@aziz2023proximity]

Data Sources: [Philly neighborhoods](https://opendataphilly.org/datasets/philadelphia-neighborhoods/), [housing sale prices (studentData)](https://github.com/mafichman/musa_5080_2024/blob/main/Midterm/data/2023/studentData.geojson), [crime incidents](https://metadata.phila.gov/#home/datasetdetails/5543868920583086178c4f8e/representationdetails/570e7621c03327dc14f4b68d/), [hydrology](https://metadata.phila.gov/#home/datasetdetails/557f30c6dcec614c29ce8b6d/representationdetails/557f30e3c579ea311699bb49/), [food retail access](https://metadata.phila.gov/#home/datasetdetails/568d4b3c13d1bebc0c2a2b0f/representationdetails/5d4c6e160f63a20011c21727/), [zoning](https://www.phila.gov/media/20220909084529/ZONING-QUICK-GUIDE_PCPC_9_9_22.pdf), [census tables](https://data.census.gov/table?g=050XX00US42101$1400000&y=2022&d=ACS%205-Year%20Estimates%20Data%20Profiles)

```{r data, echo = FALSE,quiet = TRUE, results = 'hide'}
nhoods <- 
  st_read("data/philadelphia-neighborhoods.geojson") %>%
  st_transform('EPSG:2272')

studentData <- 
  st_read("data/studentData.geojson") %>%
  st_transform('EPSG:2272')

# school <- 
#   st_read("https://opendata.arcgis.com/datasets/d46a7e59e2c246c891fbee778759717e_0.geojson") %>%
#   st_transform('EPSG:2272')
# 
# hospital <- 
#   st_read("data/DOH_Hospitals202311.geojson") %>%
#   st_transform('EPSG:2272')
# 
# metro <- 
#   st_read("https://opendata.arcgis.com/api/v3/datasets/af52d74b872045d0abb4a6bbbb249453_0/downloads/data?format=geojson&spatialRefId=4326") %>%
#   st_transform('EPSG:2272')
# 
# trolley <- 
#     st_read("https://opendata.arcgis.com/api/v3/datasets/dd2afb618d804100867dfe0669383159_0/downloads/data?format=geojson&spatialRefId=4326") %>%
#   st_transform('EPSG:2272')
# 
# park <- 
#   st_read("https://opendata.arcgis.com/datasets/d52445160ab14380a673e5849203eb64_0.geojson") %>%
#   st_transform('EPSG:2272')
# 
# water <- 
#   st_read("https://services.arcgis.com/fLeGjb7u4uXqeF9q/arcgis/rest/services/Hydrographic_Features_Poly/FeatureServer/1/query?outFields=*&where=1%3D1&f=geojson") %>%
#   st_transform('EPSG:2272')
# 
# retail <- 
#   st_read("https://opendata.arcgis.com/datasets/53b8a1c653a74c92b2de23a5d7bf04a0_0.geojson") %>%
#   st_transform('EPSG:2272')
# 
# census_tract <- 
#   st_read("data/tl_2022_42_tract/tl_2022_42_tract.shp") %>%
#   st_transform('EPSG:2272')
# 
# census <- 
#   read.csv("data/census.csv")

descriptions <- read.csv("data/descriptions.csv")

philly <- studentData[,c(74,75,48,11,16,17,18,20,22,26,34,35,44,49,58,60,69,72,76)]
descriptions <- descriptions %>%
  filter(Field.Name %in% colnames(philly))

philly <- philly %>%
  # mutate(PricePerSq = philly$sale_price / philly$total_livable_area) %>%
  #mutate(Age = 2024 - year_built) %>%
  #dplyr::select(- year_built) %>%
  #mutate(Age = case_when(Age == 2024 ~ mean(Age, na.rm = T),
  #      TRUE ~ Age)) %>%
  st_join(nhoods["NAME"])

#descriptions <- rbind(descriptions,
#                      data.frame(
#                        Field.Name = "Age", Alias = "Age", Description = "The age of housings"
#                      ))
#descriptions <- descriptions %>%
#  filter(Field.Name != "year_built")
```
```{r crimes_data, include = FALSE}
# phillyCrimes_2023 <- read.csv("data/Crimes/2023incidents_part1_part2.csv") %>%
#   dplyr::select(text_general_code, dispatch_date, lat, lng)
# phillyCrimes_2022 <- read.csv("data/Crimes/2022incidents_part1_part2.csv") %>%
#   dplyr::select(text_general_code, dispatch_date, lat, lng)
# phillyCrimes_2021 <- read.csv("data/Crimes/2021incidents_part1_part2.csv") %>%
#   dplyr::select(text_general_code, dispatch_date, lat, lng)
# phillyCrimes_2020 <- read.csv("data/Crimes/2020incidents_part1_part2.csv") %>%
#   dplyr::select(text_general_code, dispatch_date, lat, lng)
# phillyCrimes_2019 <- read.csv("data/Crimes/2019incidents_part1_part2.csv") %>%
#   dplyr::select(text_general_code, dispatch_date, lat, lng)
# 
# phillyCrimes <-
#   rbind(phillyCrimes_2023,phillyCrimes_2022,phillyCrimes_2021,phillyCrimes_2020,phillyCrimes_2019) %>%
#   mutate(dispatch_year = year(ymd(dispatch_date))) %>%
#   dplyr::select(lat, lng) %>%
#     na.omit() %>%
#     st_as_sf(coords = c("lng", "lat"), crs = "EPSG:4326") %>%
#     st_transform('EPSG:2272') %>%
#     distinct()
#
# st_write(phillyCrimes, dsn = 'data/phillyCrimes.geojson')

phillyCrimes <- 
  st_read("data/phillyCrimes.geojson")
```
```{r crimes_process}
# philly$crimes.Buffer <- philly %>% 
#     st_buffer(660) %>% 
#     aggregate(mutate(phillyCrimes, counter = 1),., sum) %>%
#     pull(counter)
philly <-
  philly %>% 
    mutate(
      # crime_nn1 = nn_function(st_coordinates(philly), 
      #                         st_coordinates(phillyCrimes), k = 1),
      # 
      # crime_nn2 = nn_function(st_coordinates(philly), 
      #                         st_coordinates(phillyCrimes), k = 2), 
      # 
      # crime_nn3 = nn_function(st_coordinates(philly), 
      #                         st_coordinates(phillyCrimes), k = 3), 
      # 
      # crime_nn4 = nn_function(st_coordinates(philly), 
      #                         st_coordinates(phillyCrimes), k = 4), 
      
      crime_nn5 = nn_function(st_coordinates(philly), 
                              st_coordinates(phillyCrimes), k = 5))

# city_hall <- metro[metro$Station == 'City Hall', 6]
# school_elem <- school %>%
#   filter(str_detect(GRADE_LEVEL, "ELEMENTARY"))
# 
# census <- census %>%
#   mutate(across(3:8, ~ as.numeric(as.character(.)))) %>%
#   mutate(NAMELSAD = str_extract(NAME, "^[^;]+")) %>%
#   select(NAMELSAD, 3:8)
# 
# calculate_nearest_distance <- function(set_points, other_layer) {
#   nearest_idx <- st_nearest_feature(set_points, other_layer)
#   st_distance(set_points, other_layer[nearest_idx, ], by_element = TRUE) %>% as.numeric()
# }
# set2 <- studentData[,74:76] %>%
#   mutate(distance_to_city_hall = st_distance(., city_hall) %>% as.numeric()) %>%
#   mutate(
#     distance_to_nearest_metro = calculate_nearest_distance(geometry, metro),
#     distance_to_nearest_hospital = calculate_nearest_distance(geometry, hospital),
#     distance_to_nearest_school = calculate_nearest_distance(geometry, school_elem),
#     distance_to_nearest_park = calculate_nearest_distance(geometry, park),
#     distance_to_nearest_water = calculate_nearest_distance(geometry, water)
#   )
# set2 <- set %>%
#   st_join(census_tract["NAMELSAD"]) %>%
#   left_join(census, by = "NAMELSAD") %>% 
#   st_join(retail[, c("LPSS_PER1000", "HPSS_PER1000")])

set <- read.csv("data/set.csv")
philly_set <- merge(philly, set, by = "musaID", all.x = FALSE, all.y = FALSE, sort = FALSE) %>%
  dplyr::select(-toPredict.y) %>%
  rename(toPredict = toPredict.x) %>%
  mutate(dist1 = ifelse(distance_to_city_hall <= 20000, distance_to_city_hall, 20000))
philly <- philly_set %>% select(-distance_to_nearest_metro, -distance_to_nearest_hospital, -distance_to_nearest_school, -distance_to_nearest_park, -NAMELSAD, -Percent_Bachelor.s.degree.or.higher, -Percent_Management..business..science..and.arts.occupations, -Percent_Different.state, -Percent_With.private.health.insurance, -HPSS_PER1000)
```


## Exploratory Data Analysis

```{r}
model_philly <- philly %>%
  filter(toPredict == "MODELLING")

ggplot() +
  geom_sf(data = nhoods, fill = "grey40", color = "grey") +
  geom_sf(data = model_philly, aes(colour = q5(sale_price)),
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels = qBr(model_philly, "sale_price"),
                   name="Quintile Breaks") +
  guides(color = guide_legend(override.aes = list(size = 3))) + 
  labs(title="Sale Price",
       subtitle = "Philadelphia, 2022",
       caption = "Figure 2.1") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```


Sale price of homes is the dependent variable to be predicted, and Figure 2.1 showed its spatial distribution across Philadelphia. Higher prices cluster in center city and the far northeast and northwest suburbs, while lower prices concentrate in west Philadelphia and north Philadelphia. This concentric pattern reflects how the city has developed, where the wealthier residents moved to the suburbs, leaving the middle ring less developed.

```{r}
stat_philly <- philly %>%
  dplyr::select(-musaID, -sale_price)

stat_philly_data <- st_drop_geometry(stat_philly)

descriptions$N <- sapply(descriptions$Field.Name, function(field) {
  sum(!is.na(stat_philly_data[[field]]))
})

selected_vars <- descriptions$Field.Name[descriptions$Variable.Type %in% c("Categorical*", "Continuous")]

descriptions <- descriptions %>% 
  rowwise() %>%
  mutate(
    Mean = ifelse(Field.Name %in% selected_vars, round(mean(stat_philly_data[[Field.Name]], na.rm = TRUE), 3), NA),
    StDev = ifelse(Field.Name %in% selected_vars, round(sd(stat_philly_data[[Field.Name]], na.rm = TRUE), 3), NA),
    Min = ifelse(Field.Name %in% selected_vars, round(min(stat_philly_data[[Field.Name]], na.rm = TRUE), 3), NA),
    Max = ifelse(Field.Name %in% selected_vars, round(max(stat_philly_data[[Field.Name]], na.rm = TRUE), 3), NA)
  ) %>%
  ungroup()

descriptions %>%
  knitr::kable(caption = "<b>Table2.1 Summary Statistics</b>", align = "cccl") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover")) %>%
  scroll_box(height = "300px", width = "800px")
```

*Note: Transformed from continuous into categorical in the regression model.

The Hedonic Pricing Model divides the total cost of property into separate costs for each characteristic according to different subgroups.[@mayor2009hedonic;@scotchmer1985hedonic] In this study, twenty-two variables are selected for the model, as summarized in Table 2.1. These include internal features like total livable area or exterior condition, amenities like crime and distance to nearest water body, as well as spatial contexts like mean family income in the census tract. The dataset’s average home has 1,333 square feet of livable space, 2.58 bedrooms and 1.07 bathrooms, with its cost at about $270,000.

```{r}
numericVars <- 
  select_if(st_drop_geometry(model_philly), is.numeric) %>% na.omit() %>%
  dplyr::select(-musaID)

cor_matrix <- cor(numericVars, use = "complete.obs")

corrplot(
  cor_matrix,
  method = "color",                             
  col = colorRampPalette(c("#6D9EC1", "white", "#E46726"))(200),  
  type = "lower",                               
  tl.pos = "l",                                 
  tl.col = "black",                      
  tl.cex = 0.7,                           
  mar = c(0, 0, 3, 0)                           
)


title(main = "Correlation across numeric variables", cex.main = 1.5, font.main = 2)
mtext("Figure 2.2", side = 1, line = 4, adj = 0.2, cex = .8)


```

Correlation of sale price and other numeric variables are presented in Figure 2.2. Mean family income shows the strongest correlation with sale price (coefficient = 0.645), followed by total livable area. Exterior and interior conditions have the highest negative correlations. Some variables exhibit high autocorrelation, which may affect interpretability of the coefficients in the final model.

```{r}
# ggplot(gather(numericVars), aes(value)) +
#   geom_histogram(bins = 50) +
#   facet_wrap(~key,nrow=4, scales = 'free_x') +
#   theme_minimal() +
#   theme(axis.text = element_blank(), axis.ticks = element_blank())

# all numeric variables
# model_philly_numeric <- st_drop_geometry(model_philly) %>% 
#   dplyr::select(sale_price, crime_nn5, 
#                 frontage, total_livable_area, 
#                 distance_to_city_hall, distance_to_nearest_water, 
#                 Estimate_Mean.family.income..dollars.,Percent_White.alone,LPSS_PER1000
#                 ) %>%
#   filter(sale_price <= 1000000) %>%
#   gather(Variable, Value, -sale_price)
# 
# ggplot(model_philly_numeric, aes(Value, sale_price)) +
#   geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#E46726") +
#   facet_wrap(~Variable, ncol = 4, scales = "free") +
#   labs(title = "Price as a function of continuous variables") +
#   theme_minimal() +
#   theme(axis.text = element_blank(), axis.ticks = element_blank())

# all factor variables
# model_philly_factor <- st_drop_geometry(model_philly) %>% 
#   dplyr::select(sale_price, 
#                 central_air, exterior_condition, fireplaces, garage_spaces, general_construction,
#                 interior_condition, number_of_bathrooms, number_of_bedrooms, quality_grade, separate_utilities,
#                 topography, zoning, building_code_description_new) %>%
#   mutate(exterior_condition = as.factor(exterior_condition),
#          fireplaces = as.factor(fireplaces),
#          garage_spaces = as.factor(garage_spaces),
#          interior_condition = as.factor(interior_condition),
#          number_of_bathrooms = as.factor(number_of_bathrooms),
#          number_of_bedrooms = as.factor(number_of_bedrooms)) %>%
#   filter(sale_price <= 1000000) %>%
#   gather(Variable, Value, -sale_price)
# 
# ggplot(model_philly_factor, aes(Value, sale_price)) +
#   geom_bar(position = "dodge", stat = "summary", fun.y = "mean") +
#   facet_wrap(~Variable, ncol = 4, scales = "free") +
#   labs(title = "Price as a function of categorical variables", y = "Mean Price") +
#   theme_minimal() +
#   theme(axis.text = element_blank(), axis.ticks = element_blank())  

## Crime cor
# model_philly %>%
#   st_drop_geometry() %>%
#   dplyr::select(sale_price, starts_with("crime")) %>%
#   filter(sale_price <= 1000000) %>%
#   gather(Variable, Value, -sale_price) %>% 
#    ggplot(aes(Value, sale_price)) +
#      geom_point(size = .5) + geom_smooth(method = "lm", se=F, colour = "#E46726") +
#      facet_wrap(~Variable, nrow = 1, scales = "free") +
#      labs(title = "Price as a function of crimes") +
#      theme_minimal()
```

## Feature Engineering

Transformations of variables can sometimes improve model performance. Three types of transformations are applied in this study: logarithmic transformation, reclassification, and piecewise splitting, with examples shown below.

```{r}
model_philly_numeric <- st_drop_geometry(model_philly) %>% 
  mutate(total_livable_area_log = log(total_livable_area + 1)) %>%
  dplyr::select(total_livable_area, total_livable_area_log) %>%
  filter(total_livable_area <= 2000000)

plot1 <- ggplot(model_philly_numeric, aes(x = total_livable_area)) +
  geom_histogram(bins = 30, fill = "#6D9EC1", color = "black", alpha = 0.5) +
  labs(title = "Original Total Livable Area") +
  xlim(0, 7500) + 
  coord_cartesian(ylim = c(0, 8000)) + 
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    axis.title.x = element_blank()
  )


plot2 <- ggplot(model_philly_numeric, aes(x = total_livable_area_log)) +
  geom_histogram(bins = 30, fill = "#6D9EC1", color = "black", alpha = 0.5) +
  labs(title = "Log-transformed Total Livable Area") +
  xlim(5, 9) + 
  coord_cartesian(ylim = c(0, 8000)) +  
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, hjust = 0.5),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank() 
  )


combined_plot <- plot1 + plot2 + 
  plot_layout(widths = c(1, 1)) + 
  plot_annotation(
    title = "Distribution of Total Livable Area",
       caption = "Figure 2.3",
    theme = theme(plot.title = element_text(size = 18, face = "bold"),
    plot.caption = element_text(hjust = 0))
  )

combined_plot
```

Figure 2.3 shows a typical use of log-transformation to the variable total livable area, making a right-skewed distribution more normal, fitting the assumptions of the OLS framework better. 

```{r}
philly_f <- philly %>% 
  mutate(
    exterior_condition = case_when(
      is.na(exterior_condition) | exterior_condition == 1 ~ "1",
      exterior_condition %in% c(2, 3) ~ "2",
      exterior_condition == 4 ~ "3",
      TRUE ~ "4"
    ),
    exterior_condition = factor(exterior_condition)
  )

count_data <- philly %>%
  group_by(exterior_condition) %>%
  summarise(count = n())

mean_price_data <- philly %>%
  group_by(exterior_condition) %>%
  summarise(mean_sale_price = mean(sale_price, na.rm = TRUE))

count_data_f <- philly_f %>%
  group_by(exterior_condition) %>%
  summarise(count = n())

mean_price_data_f <- philly_f %>%
  group_by(exterior_condition) %>%
  summarise(mean_sale_price = mean(sale_price, na.rm = TRUE))


plot1 <- ggplot(count_data, aes(x = exterior_condition, y = count)) +
  geom_bar(stat = "identity", fill = "#6D9EC1", alpha = 0.8, width = 0.6) +
  theme_minimal() +
  theme(
    legend.position = "none", 
    plot.title = element_text(size = 12),
    axis.title.x = element_blank()
  )

plot2 <- ggplot(mean_price_data, aes(x = exterior_condition, y = mean_sale_price)) +
  geom_bar(stat = "identity", fill = "#E46726", alpha = 0.8, width = 0.6) +
  theme_minimal() +
  theme(
    legend.position = "none", 
    plot.title = element_text(size = 12),
    axis.title.x = element_blank()
  )

plot3 <- ggplot(count_data_f, aes(x = exterior_condition, y = count)) +
  geom_bar(stat = "identity", fill = "#6D9EC1", alpha = 0.8, width = 0.6) +  
  theme_minimal() +
  theme(
    legend.position = "none", 
    plot.title = element_text(size = 12),
    axis.title.x = element_blank()
  )

plot4 <- ggplot(mean_price_data_f, aes(x = exterior_condition, y = mean_sale_price)) +
  geom_bar(stat = "identity", fill = "#E46726", alpha = 0.8, width = 0.6) +  
  theme_minimal() +
  theme(
    legend.position = "none", 
    plot.title = element_text(size = 12),
    axis.title.x = element_blank()
  )


combined_plot <- (plot1 | plot2) / (plot3 | plot4) + 
  plot_annotation(
    title = "Exterior Condition and Sale Price",
    subtitle = "Before (Left) and After (Right) Reclassification",
    caption = "Figure 2.4",
    theme = theme(plot.title = element_text(size = 18, face = "bold"),
    plot.caption = element_text(hjust = 0))
  )

combined_plot

```

Reclassification includes converting a numeric variable into categorial one, and recoding it into fewer categories, as Figure 2.4. This applies to variables that have too few observations in some categories or have mere differences across categories, making the model more robust.

```{r}

model_philly_numeric <- st_drop_geometry(model_philly) %>% 
  dplyr::select(sale_price, distance_to_city_hall) %>%
  filter(sale_price <= 1000000) %>%
  mutate(DistanceCategory = ifelse(distance_to_city_hall <= 20000, "<= 20000", "> 20000"))

plot1 <- ggplot(subset(model_philly_numeric, DistanceCategory == "<= 20000"),
                aes(distance_to_city_hall, sale_price)) +
  geom_point(size = 0.5, color = "#6D9EC1", alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "#E46726") +
  ylab("Sale Price") +
  ggtitle("<= 20000") +  # 添加小标题
  scale_x_continuous(breaks = seq(0, 20000, by = 10000)) +
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        plot.title = element_text(size = 12, hjust = 0.5)) 

plot2 <- ggplot(subset(model_philly_numeric, DistanceCategory == "> 20000"),
                aes(distance_to_city_hall, sale_price)) +
  geom_point(size = 0.5, color = "#6D9EC1", alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "#E46726") +
  ggtitle("> 20000") +  # 添加小标题
  theme_minimal() +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        plot.title = element_text(size = 12, hjust = 0.5)) 

combined_plot <- plot1 + plot2 + 
  plot_layout(widths = c(1, 4)) + 
  plot_annotation(
    title = "Price as a function of Distance to City Hall",
    caption = "Figure 2.5",
    theme = theme(plot.title = element_text(size = 18, face = 'bold'),
                  plot.caption = element_text(hjust = 0))
  )

combined_plot

```

Cutting continuous variables into pieces is a way of dealing with non-linear relationships, as is shown in Figure 3.3. The sale price sharply decreases and slightly goes up as distance to city hall increases, reflecting the concentric development structure discussed in Figure 2.5. In this case, we added a “dist1” variable, assigning actual values if its distance is less than 20000 ft, or 20000 ft otherwise. This transformation will help achieve the effect of piecewise function in linear regressions. 

```{r}
philly_fac <- philly %>%
  mutate(
    # basements = case_when(
    #   basements %in% c("0", "1", "4", "A") ~ "B",   
    #   TRUE ~ "A"                               
    # ),
    # basements = factor(basements),
    
    central_air = case_when(
      central_air %in% c("1", "Y") ~ "Y",  
      TRUE ~ "N"                          
    ),
    central_air = factor(central_air),
    
    exterior_condition = case_when(
      is.na(exterior_condition) | exterior_condition == 1 ~ "1",    
      exterior_condition %in% c(2, 3) ~ "2",                        
      exterior_condition == 4 ~ "3",                                
      TRUE ~ "4"                      
    ),
    exterior_condition = factor(exterior_condition),
    
    fireplaces = case_when(
      is.na(fireplaces) | fireplaces == 0 | fireplaces == 1 ~ "0",                    
      TRUE ~ "1"                                
    ),
    fireplaces = factor(fireplaces),
    
    # fuel = case_when(
    #   is.na(fuel) | fuel == "" ~ "X",  
    #   TRUE ~ "A"                       
    # ),
    # fuel = factor(fuel),
    
    garage_spaces = case_when(
      is.na(garage_spaces) | garage_spaces == 0 ~ "0",    
      garage_spaces == 1 ~ "1",      
      TRUE ~ "2"                     
    ),
    garage_spaces = factor(garage_spaces),
    
    general_construction = case_when(       
      general_construction %in% c("A ", "B ", "D ") ~ "A",  
      general_construction == "3 " ~ "C",        
      TRUE ~ "B"                                 
    ),
    general_construction = factor(general_construction),
    
    interior_condition = case_when(
      interior_condition %in% c(0, 1, 2, 3) ~ "1",         
      interior_condition %in% c(4, NA) ~ "2",        
      TRUE ~ "3"       
    ),
    interior_condition = factor(interior_condition),
    
    number_of_bathrooms = case_when(
      number_of_bathrooms == 0 ~ "0",                   
      number_of_bathrooms == 1 ~ "1",                   
      number_of_bathrooms %in% c(2, NA) ~ "2",          
      number_of_bathrooms == 3 ~ "3",                   
      TRUE ~ "4"                                        
    ),
    number_of_bathrooms = factor(number_of_bathrooms),
    
    number_of_bedrooms = case_when(
      number_of_bedrooms %in% c(0, 31) | is.na(number_of_bedrooms) ~ "0",  
      number_of_bedrooms %in% c(1, 2) ~ "1",    
      number_of_bedrooms == 3 ~ "2",            
      number_of_bedrooms == 4 ~ "3",            
      number_of_bedrooms %in% c(5, 6) ~ "4",    
      number_of_bedrooms %in% c(7, 8, 9) ~ "5" 
    ),
    number_of_bedrooms = factor(number_of_bedrooms),
    
    # parcel_shape = case_when(
    #   parcel_shape %in% c("C", "E") ~ "A",  
    #   parcel_shape == "A" ~ "B",            
    #   TRUE ~ "C"                            
    # ),
    # parcel_shape = factor(parcel_shape),
    
    quality_grade = case_when(
      quality_grade %in% c("A+", "A", "A-", "X", "X-") ~ "1",           
      quality_grade %in% c("B+", "B", "B-", "3", "S+") ~ "2",
      TRUE ~ "3"                                             
    ),
    quality_grade = factor(quality_grade),
    
    separate_utilities = case_when(
      separate_utilities %in% c("A", "C") ~ "B",  
      TRUE ~ "A"                                 
    ),
    separate_utilities = factor(separate_utilities),
    
    # street_direction = case_when(
    #   is.na(street_direction) | street_direction == "" | street_direction == "S" ~ "A",
    #   TRUE ~ "B"                           
    # ),
    # street_direction = factor(street_direction),
    
    topography = case_when(
      topography == "B" ~ "B",
      TRUE ~ "A"
    ),
    topography = factor(topography),
    
    # type_heater = case_when(
    #   type_heater == "D" ~ "B",            
    #   TRUE ~ "A"                           
    # ),
    # type_heater = factor(type_heater),
    
    building_code_description_new = case_when(
      building_code_description_new %in% c("COLONIAL", "OLD STYLE", "ROW MODERN", "ROW OLD STYLE", "TUDOR", "TWIN BUNGALOW") ~ "1",
      building_code_description_new %in% c("ROW POST WAR", "ROW TYPICAL", "TWIN CONVENTIONAL") ~ "3",
      building_code_description_new %in% c("OTHER", "ROW PORCH FRONT") ~ "4",
      TRUE ~ "2"
    ),
    building_code_description_new = factor(building_code_description_new),
    
    NAME = case_when(
      NAME %in% c("CHINATOWN", "CRESTMONT_FARMS", "EAST_PARK", "MECHANICSVILLE", 
                  "PENNYPACK_PARK", "UNIVERSITY_CITY", "WISSAHICKON_PARK", "WOODLAND_TERRACE") ~ "OTHERS",
      TRUE ~ NAME 
    ),
    NAME = factor(NAME)
  )
philly <- philly_fac

model_philly <- philly %>%
  filter(toPredict == "MODELLING")

st_drop_geometry(model_philly) %>% 
  dplyr::select(sale_price, total_livable_area, crime_nn5, distance_to_city_hall, Estimate_Mean.family.income..dollars.) %>%
  filter(sale_price <= 2000000 & crime_nn5 <= 1000 & total_livable_area <= 7500) %>%
  gather(Variable, Value, -sale_price) %>%
  ggplot(aes(Value, sale_price)) +
  geom_point(size = 0.5, colour = "#6D9EC1", alpha = 0.5) +  
  geom_smooth(method = "lm", se = FALSE, colour = "#E46726") + 
  facet_wrap(~Variable, ncol = 2, scales = "free") +
  labs(title = "Price as a function of continuous variables",
       caption = "Figure 2.6") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    plot.caption = element_text(hjust = 0)
  )
```

Figure 2.6 includes scatterplots for sale price against four selected continuous variables. Besides “distance to city hall” we have addressed, positive relationships between sale price and the other three variables are explicit. The points in the plots are dispersed rather than being around the line, showing the sense of Hedonic Pricing Model’s aim to value all services to define a total price, reducing the variance from any single variable.

```{r map1}
ggplot() +
  geom_sf(data = nhoods, , fill = "grey40", color = "grey", na.rm = T) +
  geom_sf(data = philly %>% filter(!is.na(LPSS_PER1000)), aes(colour = q5(LPSS_PER1000)), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(philly,"LPSS_PER1000"),
                   name="Quintile\nBreaks") +
  guides(color = guide_legend(override.aes = list(size = 3))) + 
  labs(title="Low-Produce Supply Stores",
       subtitle = "per 1000 People",
       caption = "Figure 2.7") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```

Low-produce supply stores (LPSS) include dollar stores, pharmacies and convenience stores. It is a measure of accessibility to affordable stores, having high density in areas with lower income in north and west Philadelphia, as shown in Figure 2.7. When aligned with other variables, LPSS distinguishes these neighborhoods well and enhances model accuracy.

```{r map2}
ggplot() +
  geom_sf(data = nhoods, fill = "grey40", color = "grey", na.rm = T) +
  geom_sf(data = philly %>% filter(!is.na(exterior_condition)), aes(colour = exterior_condition), 
          show.legend = "point", size = .75) +
  scale_colour_manual(values = colorRampPalette(c("#E46726", "#6D9EC1"))(4)
                   ) +
  guides(color = guide_legend(override.aes = list(size = 3))) + 
  labs(title="Exterior Condition",
       caption = "Figure 2.8") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```

The spatial distribution of exterior conditions is as Figure 2.8 (1 = best, 4 = worst). Homes with the best exterior conditions are close to the center city, and west Philadelphia shows a mix of both well- and ill-conditioned homes, instead of corresponding only with the wealthiness of the neighborhoods.

```{r map3}
ggplot() +
  geom_sf(data = nhoods, fill = "grey40", color = "grey", na.rm = TRUE) +
  geom_sf(data = philly %>% filter(!is.na(zoning)), aes(colour = zoning), 
          show.legend = "point", size = 0.75) +
  scale_colour_manual(values = c(
    "RM1" = "#FCB951", "RM2" = "#FCB951", "RM3" = "#FCB951", "RM4" = "#FCB951",
    "RMX1" = "#E58425", "RMX2" = "#E58425", "RMX3" = "#E58425",
    "RSA1" = "#F8EE68", "RSA2" = "#F8EE68", "RSA3" = "#F8EE68", "RSA4" = "#F8EE68", 
    "RSA5" = "#F8EE68", "RSA6" = "#F8EE68",
    "RSD1" = "#FFF5C4", "RSD2" = "#FFF5C4", "RSD3" = "#FFF5C4",
    "RTA1" = "#CDB650"
  )) +
  guides(color = guide_legend(override.aes = list(size = 3), ncol = 2)) + 
  labs(title = "Zoning", subtitle = "Philadelphia, 2022",
       caption = "Figure 2.9") +
  mapTheme() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    plot.subtitle = element_text(size = 12),
    panel.border = element_rect(colour = "black", fill = NA, size = 1)
  )

```

Figure 2.9 visualizes the zoning status, colored in the official colors. The most common type of zoning is RSA (Residential Single-Family Attached). RM (Residential Multi-Family), with higher density, are clustered along Board St, near center city and a couple of areas in west Philadelphia, while RSD (Residential Single-Family Detached), with lower density, are spread across far northwest and northeast suburbs.

```{r}
# cor_philly <- 
#   st_drop_geometry(model_philly) %>%
#   filter(sale_price <= 1000000,
#          total_livable_area < 10000) %>%
#   dplyr::select(sale_price, total_livable_area)
# 
# cor.test(cor_philly$total_livable_area,
#          cor_philly$sale_price, 
#          method = "pearson")
# 
# 
# # Calculate predicted prices
# cor_philly$predicted_price <- predict(lm(sale_price ~ total_livable_area, data = cor_philly), newdata = cor_philly)
# ggscatter(cor_philly,
#           x = "total_livable_area",
#           y = "sale_price",
#           color = "#6D9EC1", size = 1, alpha = 0.6) +
#   geom_point(aes(y = predicted_price), color = "#E46726", size = 1, alpha = 0.6) +
#   stat_cor(label.x = 4000, label.y = 250000, hjust = 0) +
#   labs(title = "Price as a function of living area", 
#        subtitle = "With predicted prices; Sale prices <= $1 mil.",
#        x = "Total Livable Area",
#        y = "Sale Price") +
#   theme_minimal() +
#   theme(plot.title = element_text(size = 18, face = "bold"),
#         plot.subtitle = element_text(size = 12)) 
```

# Methods

The core of our algorithm is Ordinary Least Square (OLS) regression model. We used 9 continuous variables and 13 reclassified categorical variables as independent variables and sale price as the dependent variable. 

To build and evaluate our model, we split the dataset into two parts: 60% as the training set to fit the model, and 40% as the test set to evaluate its accuracy. The model was tested using Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and prediction v.s. actual value scatter plot.

To ensure the accuracy of the model, we applied a 100-fold cross validation process. This divides the data into 100 subsets, repeatedly testing the model to see how well it performs across different samples. Finally, we examined the generalizability of the model across different neighborhood contexts by observing the distribution of spatial lag, calculating Moran’s I (a measure of spatial clustering in model errors), and testing the model in different neighborhood settings.

Analyses were conducted using R version 4.4.1.

# Results

Using the features selected above, our model explains 76% of the variation in price and produces average errors of 36% relative to housing prices. In terms of cross-validation, our model was well-trained on the available variables and shows high accuracy for low-priced houses. However, it demonstrates less consistency and a slight positive spatial autocorrelation, suggesting the influence of unaccounted factors. At the urban scale, our model is less effective at predicting prices in low-income neighborhoods and reveals a significant discrepancy between high- and low-income areas, indicating a further development in generalizability.

## Our Regression Model: explaining 76% of the prices

To improve the model's accuracy and generalizability, we randomly split the dataset into 60% for training the model and 40% for testing its goodness of fit. Using the selected features, OLS regression was performed on the training set.

```{r}
set.seed(34)
inTrain <- createDataPartition(
              y = paste(model_philly$general_construction, 
                       model_philly$topography,
                       model_philly$quality_grade,
                        model_philly$NAME),
                        
              p = .60, list = FALSE)
# [row,column] select all columns
philly.training <- model_philly[inTrain,] 
philly.test <- model_philly[-inTrain,]

reg.training <- lm(sale_price ~ log(total_livable_area+1) + total_livable_area + crime_nn5 + LPSS_PER1000 +
              log(dist1+1) +log(distance_to_city_hall+1) + log(distance_to_nearest_water+1) +
              Estimate_Mean.family.income..dollars. + Percent_White.alone + log(frontage+1) +  
              
              central_air + exterior_condition + fireplaces + garage_spaces + general_construction + 
              interior_condition + number_of_bathrooms + number_of_bedrooms + quality_grade + 
              separate_utilities + topography + building_code_description_new + zoning + 
              NAME,
    data = st_drop_geometry(philly.training))

kable(summary(reg.training)$coefficients, digits = 3,format = "html",caption = "<b>Table 4.1 OLS Regression Results</b>", align = "ccccc") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover")) %>%
  scroll_box(height = "300px")
```


In our model, the features explain approximately 76% of the variation in price (Adjusted R^2^ = `r scales::percent(summary(reg.training)$adj.r.squared, accuracy = 0.01)`) and most of their coefficients are statistically significant (p<0.05). Several features, such as general construction and architectural styles, are converted to categorical variables, allowing their coefficients to be estimated and linked to housing prices. The remaining insignificant coefficients are of neighborhood names or zoning codes, which are less likely to regroup due to spatial disparities.

## Accuracy: better for sales priced below $1,000,000

To dictate how useful the model is for decision making, we used testing set to analyse goodness of fit indicators.

```{r}
philly.test <-
  philly.test %>%
  mutate(Regression = "Baseline Regression",
         sale_price.Predict = predict(reg.training, philly.test),
         sale_price.Error = sale_price.Predict - sale_price,
         sale_price.AbsError = abs(sale_price.Predict - sale_price),
         sale_price.APE = (abs(sale_price.Predict - sale_price)) / sale_price) %>%
  filter(sale_price < 5000000)

MAE <- mean(philly.test$sale_price.AbsError, na.rm = T)
MAPE <- mean(philly.test$sale_price.APE, na.rm = T)
acc <- data.frame(MAE, MAPE)

acc %>%
  knitr::kable(caption = "<b>Table 4.2 MAE and MAPE of the testing dataset</b>", align = "cc") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover"))
```

The Mean Absolute Error (MAE) is $`r round(MAE,2)`, representing the average difference between predicted and observed prices. The relatively high value reflects the diversity in housing prices, suggesting a limitation for linear regression. The Mean Absolute Percent Error (MAPE) indicates that the prediction error amounts to `r scales::percent(MAPE, accuracy = 0.01)` of the housing prices on average.

```{r}
ggplot(
  philly.test, aes(sale_price.Predict, sale_price)) +
  geom_point(size = .5) + 
  geom_smooth(method = "lm", se=F, colour = "#6D9EC1") +
  geom_abline(intercept = 0, slope = 1, color="#E46726",size=1) +
  theme_minimal() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = ggtext::element_markdown(size = 12),
        plot.caption = element_text(hjust = 0)) +
  labs(title = 'Predicted sale price as a function of observed price', 
       subtitle = glue("<span style='color:#E46726;'>Perfect prediction</span> vs. <span style='color:#6D9EC1;'>Average prediction</span>"),caption = "Figure 4.1",
       x = "Predicted Sale Price",
       y = "Observed Sale Price")
```

Given the high MAE and MAPE, data visualization was used to compare predicted and observed prices. The red and blue lines nearly overlap, indicating the model performs well overall. However, the slight deviation suggests that, on average, the model's predictions are a little higher than the observed prices. Examining the data points further reveals that prediction accuracy decreases as prices rise, confirming our concerns about the variability in the higher price ranges of the dataset. This suggests that our model performs particularly well for lower-valued housing prices.

## Generalizability: cross-validation shows less consistency

After making predictions on a single hold-out test set, we partitioned the dataset into 100 equal-sized subsets, training on the remaining data and testing on each subset. This process is known as the K-fold cross-validation method.

```{r}
fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(sale_price ~ log(total_livable_area+1) + total_livable_area + crime_nn5 + LPSS_PER1000 +
              log(dist1+1) +log(distance_to_city_hall+1) + log(distance_to_nearest_water+1) +
              Estimate_Mean.family.income..dollars. + Percent_White.alone + log(frontage+1) +  
              
              central_air + exterior_condition + fireplaces + garage_spaces + general_construction + 
              interior_condition + number_of_bathrooms + number_of_bedrooms + quality_grade + 
              separate_utilities + topography + building_code_description_new + zoning + 
              NAME,
    
    data = st_drop_geometry(model_philly),
    method = "lm", trControl = fitControl, na.action = na.pass)

kable(reg.cv$results, digits = 3,caption = "<b>Table 4.3 Cross-Validation Results</b>", align = "ccccccc") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover"))
```


```{r}
Mean <- mean(reg.cv$resample[,3])
SD <- sd(reg.cv$resample[,3])
stat_MAE <- data.frame(Mean, SD)

stat_MAE %>%
  knitr::kable(caption = "<b>Table 4.4 Mean and standard deviation of the cross-validation MAE</b>", align = "cc") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover"))
```

The standard deviation of MAE (`r round(SD,2)`) reflects significant variation across the 100 folds. Additionally, the mean of MAE in cross-validation (`r round(Mean,2)`) is quite similar to the MAE in our test set (`r round(MAE,2)`), indicating that the model was well-trained on the existing variables and therefore shows an average error.

```{r}
ggplot(data = data.frame(mae = reg.cv$resample[,3]),aes(x = mae)) +
  geom_histogram(color = "white", fill = "#6D9EC1") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 50),
                     labels = function(x) ifelse(x %% 5000 == 0, x, "")) +
  labs(title = "Distribution of MAE", 
       subtitle = "K fold cross validation; k=100.",
       caption = "Figure 4.2",
       x = "Mean Absolute Error", y = "Count") +
  theme_minimal() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        plot.caption = element_text(hjust = 0)) +
  geom_vline(aes(xintercept=mean(mae, na.rm=T)),
               color="#E46726", linetype="dashed", size=1) +
  geom_vline(aes(xintercept= MAE),
               color="#E46726", linetype="dashed", size=.8, alpha = .8) +
  annotate(geom = "text", label = paste("Mean of MAE:", round(Mean, 2)), # Insert correlation here
    x = 67000, y = 10, 
    hjust = 0, size = 4, color = "#E46726") +
  annotate(geom = "text", label = paste("MAE in the test set:\n", round(MAE, 2)), # Insert correlation here
    x = 61000, y = 9, 
    hjust = 1, size = 4, color = "#E46726", alpha = .8) 
```

Visualized in a histogram, the distribution of MAE in cross-validation peaks around 63000 and exhibits a long right tail. This suggests that the model predicts inconsistently and may be unreliable for predicting houses that have not been sold recently.

## Generalizability: positive spatial autocorrelation exists

```{r}
philly.test_predict <-
  philly.test[which(philly.test$sale_price.Error != 0),]

coords.test <-  st_coordinates(philly.test_predict) 

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")
philly.test_predict$lagPriceError <- lag.listw(spatialWeights.test, philly.test_predict$sale_price.Error)

philly.test <- philly.test_predict

ggplot() +
  geom_sf(data = nhoods, fill = "grey40", color = "grey", na.rm = T) +
  geom_sf(data = philly.test_predict, aes(colour = q5(sale_price.Error), na.rm = T),
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(philly.test_predict,"sale_price.Error"),
                   name="Quintile Breaks") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(title="Sale price errors on the test set",
       caption = "Figure 4.3") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```


What might be causing the high MAE? Although our model incorporates internal characteristics, public services/amenities, and some spatial features, other factors influencing the spatial distribution of home prices remain unexplored. As the map illustrates, sale price errors in Philadelphia are generally randomly distributed, but with some clustering both within and across neighborhoods. How much do our model errors cluster? Calculating the average weighted model error of its five nearest neighbors as the "spatial lag", we delved deeper into the spatial autocorrelation test.

```{r}
cor_error <- cor(philly.test_predict$lagPriceError, philly.test_predict$sale_price.Error, method = "pearson")
ggplot(philly.test_predict, aes(x = lagPriceError, y = sale_price.Error))+
     geom_point(size = .5, color = "#6D9EC1") + geom_smooth(method = "lm", se=F, colour = "#E46726") +
     labs(title = "Error as a function of the spatial lag of price",
          x = "Spatial lag of errors (Mean error of 5 nearest neighbors)", y = "Sale price errors",
       caption = "Figure 4.4") +
  annotate(geom = "text", label = paste("Pearson Correlation:", round(cor_error, 3)), # Insert correlation here
    x = -700000, y = -1000000, 
    hjust = 0, vjust = 2, 
    size = 4) +
     theme_minimal() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.caption = element_text(hjust = 0))
```

Comparing the spatial lag with the actual values helps estimate the degree of spatial autocorrelation. The relationship visualized above shows that as home price errors increase, nearby home price errors tend to rise as well. The correlation is `r round(cor_error,3)`, which is marginal but significant.

```{r}
philly.test_nonzero <- philly.test %>%
  filter(sale_price.Error != 0)
moranTest <- moran.mc(philly.test_nonzero$sale_price.Error, 
                      spatialWeights.test, nsim = 999)

ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#E46726",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="<span style='color:#E46726;'>Observed</span> and <span style='color:#7F7F7F;'>permuted</span> Moran's I",
       x="Moran's I",
       y="Count",
       caption = "Figure 4.5") +
  annotate(geom = "text", label = paste("Statistic:", round(moranTest$statistic,3),"\np-value:", moranTest$p.value), # Insert correlation here
    x = 0.2, y = 300, 
    hjust = 0, 
    size = 4) +
  theme_minimal() +
  theme(plot.title = ggtext::element_markdown(size = 18, face = "bold"),
        plot.caption = element_text(hjust = 0))
```

Another approach to measure spatial autocorrelation is Moran's I, where a positive value close to one indicates strong positive spatial autocorrelation. The histogram above shows 999 randomly permuted I values, with the observed I marked by the orange line. The observed I, higher than all random permutations, confirms spatial autocorrelation. An I of `r round(moranTest$statistic,3)` seems marginal, but a p-value of `r moranTest$p.value` still indicates statistically significant clustering.

Both the spatial lag and Moran’s I test show that our model errors exhibit a slight positive spatial autocorrelation, suggesting the presence of unaccounted factors.


## Generalizability: less effective for low-priced neighborhoods and low-income tracts

How does the spatial autocorrelation manifest in our model? From the perspective of geospatial features, including neighborhoods and median income, we further analysed the spatial process of sale price predictions and tested the generalizability across urban contexts.

```{r}
nhoods_model <- st_drop_geometry(philly.test) %>%
  group_by(NAME) %>%
  summarise(mean.MAPE = mean(sale_price.APE, na.rm = T)) %>%
  ungroup() %>%
  left_join(nhoods) %>%
  st_sf()

ggplot() +
  geom_sf(data = nhoods, fill = "transparent", color = "grey") +
  geom_sf(data = nhoods_model, aes(fill = mean.MAPE), color = "grey") +
  scale_fill_gradient(low = "#6D9EC1", high = "#E46726", name = "MAPE") +
  labs(title = "Mean test set MAPE by neighborhood",
       caption = "Figure 4.6") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```

The MAPE by neighborhood reveals significantly less accurate predictions in North and West Philadelphia (highlighted in red). The vacant areas have no housing sales data, including northern Center City, University City, Northeast Philadelphia Airport and its surroundings, southern South Philadelphia, and parks. In [North Philadelphia](https://en.wikipedia.org/wiki/North_Philadelphia#Neighborhoods), the red areas are predominantly home to Hispanic and Black residents, while the surrounding population is more diverse, contributing to the high MAPE. In [West Philadelphia](https://en.wikipedia.org/wiki/West_Philadelphia#History), the impact of the University of Pennsylvania’s role in gentrification in the east and rising crime in the west have led to deteriorating areas with high MAPE. Both red areas also have lower sale prices, confirming the spatial pattern of model generalizability.


```{r}
nhoods_model <- left_join(nhoods_model,
  st_drop_geometry(philly.test) %>%
    group_by(NAME) %>%
    summarise(meanPrice = mean(sale_price, na.rm = T))
) 
ggplot(data = st_drop_geometry(nhoods_model)) +
  geom_point(aes(x = meanPrice, y = mean.MAPE), size = 2, color = "#E46726", alpha = 0.7) +
  geom_vline(aes(xintercept= 375000),
               color="#6D9EC1", linetype="dashed", size=.8, alpha = .8) +
  geom_hline(aes(yintercept= .4),
               color="#6D9EC1", linetype="dashed", size=.8, alpha = .8) +
  labs(title = "MAPE as a function of mean price by neighborhood",
       x = "Mean Price by Neighborhood",
       y = "MAPE by Neighborhood",
       caption = "Figure 4.7") +
  theme_minimal() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.caption = element_text(hjust = 0)) +
  annotate(geom = "text", label = paste("(275000,0.4)"),
    x = 275000, y = 0.4, 
    hjust = -.8, vjust = -1, size = 4, color = "#6D9EC1", alpha = .8)
```

Upon further examining the relationship between price and MAPE across neighborhoods, it is evident that MAPE decreases as the mean price increases up to $375,000, but starts to rise when the mean price exceeds this threshold. In our model, mean prices between $125,000 and $500,000 are associated with relatively lower MAPE. The spatial pattern of MAPE (see Figure 4.6) also shows that lower-priced, declining areas tend to have higher MAPE. These two graphs highlight that our model is more effective in neighborhoods with mid-range prices and that the socioeconomic context of neighborhoods impacts pricing.


```{r include = FALSE}
census_api_key("e62580f74ef222beadd9dd2fbaf48ff130b31c4a", overwrite = TRUE)
acs_variable_list.2022 <- load_variables(2022, #year
                                         "acs5", #five year ACS estimates
                                         cache = TRUE)

tracts22 <- get_acs(geography = "tract",
                    variables = c("B01003_001E", "B01001A_001E","B06011_001E"), 
                    year=2022, 
                    state=42, 
                    county=101, 
                    geometry=TRUE, 
                    output="wide") %>%
  st_transform('EPSG:2272') %>%
  rename(TotalPop = B01003_001E, 
         TotalWhites = B01001A_001E,
         MedInc = B06011_001E) %>%
  dplyr::select(-NAME, -starts_with("B")) %>%
  mutate(year = "2022",
         percentWhite = TotalWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(MedInc > mean(MedInc, na.rm = T), "High Income", "Low Income"))
```
```{r}
ggplot() + 
  geom_sf(data = tracts22, fill = "transparent", color = "grey") +
  geom_sf(data = na.omit(tracts22), aes(fill = incomeContext), color = "grey90") +
  scale_fill_manual(values = c("#E46726", "#6D9EC1"), name="Income Context") +
  labs(title = "Tracts grouped by income",
       subtitle = "Philadelphia, 2022",
       caption = "Figure 4.8") +
  mapTheme() + 
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```
```{r}
income_table <- st_join(philly.test, tracts22) %>%
  group_by(incomeContext) %>%
  summarise(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(incomeContext, mean.MAPE) %>%
  dplyr::select(-"<NA>") %>%
  mutate('No Context' = scales::percent(MAPE))

income_table %>%
  knitr::kable(caption = "<b>Table 4.5 Test set MAPE by tract income context</b>", align = "ccc") %>%
  kableExtra::kable_material(lightable_options = c("striped", "hover"))
```

At the urban scale, we compared MAPE across different income contexts to assess the generalizability of our model. Tracts with median incomes above the citywide mean were designated as 'High Income', effectively dividing Philadelphia into two categories. The nearly 1:2 ratio in MAPE highlights a significant difference in the model’s goodness of fit, indicating higher accuracy in predicting housing prices in high-income areas. The neighborhoods with high MAPE (see Figure 4.6) fall predominantly within the low-income group, suggesting a connection between race, crime, income, and housing prices.

## Challenge time

Using our model, the predicted values for where ‘toPredict’ is both “MODELLING” and “CHALLENGE” are as follows.

```{r}
philly_finish <- philly %>%
   mutate(sale_price.Predict = predict(reg.training, philly))

ggplot() +
  geom_sf(data = nhoods, fill = "grey40", color = "grey", na.rm = T) +
  geom_sf(data = philly_finish %>% filter(!is.na(sale_price.Predict)), aes(colour = q5(sale_price.Predict), na.rm = T),
          show.legend = "point", size = .75) +
  scale_colour_manual(values = palette5,
                   labels=qBr(philly_finish,"sale_price.Predict"),
                   name="Quintile Breaks") +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(title="Predicted Values of 'Modelling' and 'Challenge'",
       subtitle = "Philadelphia, 2022",
       caption = "Figure 4.9") +
  mapTheme() +
  theme(plot.title = element_text(size = 18, face = "bold"),
        plot.subtitle = element_text(size = 12),
        panel.border = element_rect(colour = "black", fill=NA, size=1))
```

# Discussion

Our model effectively predicts 76% of the variation in housing prices, particularly with high accuracy for sales priced below $1,000,000. Our logarithmic transformation and piecewise splitting of distance to city hall is both interesting and essential to the model. Other key features such as distance to the city center, neighborhood names, and zoning numbers significantly reduce prediction errors by approximately 20% when included in training. The Mean Absolute Error is $`r round(MAE,2)` and the Mean Absolute Percent Error is `r scales::percent(MAPE, accuracy = 0.01)`. Prediction errors remain high due to the dataset's wide price variation and unaccounted factors influencing spatial dynamics. From the perspective of urban context, the model performs poorly in North Philadelphia, where clustering of Hispanic and Black residents presents challenges, and in West Philadelphia, where rising crime and gentrification add complexity. These decaying factors contribute to lower housing prices and a more intricate spatial process. Nonetheless, the model performs well in neighborhoods with mid-range housing prices, where the larger dataset provides stronger training and testing opportunities.

# Conclusion

I would recommend our model to Zillow for customers looking to predict mid-range housing prices in Philadelphia. The model is well-trained and accounts for internal characteristics, public services/amenities, and spatial features, demonstrating a strong fit within the context of Philadelphia. While there is some spatial autocorrelation present and OLS regression has its limitations, we plan to explore additional socioeconomic factors that influence the spatial process of housing prices, and apply non-linear regression and other machine learning techniques to further enhance the model.

# References





